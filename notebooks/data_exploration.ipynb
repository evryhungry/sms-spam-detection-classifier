{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8be7c43fc19f6d",
   "metadata": {},
   "source": [
    "# SMS Spam Detection: Test & Visualization\n",
    "\n",
    "이 노트북에서는\n",
    "1. 전처리된 데이터(`train.csv`, `valid.csv`, `test.csv`)를 로드\n",
    "2. 학습된 모델(`best_model_epoch*.pt`)을 불러와 테스트셋으로 성능 평가\n",
    "3. Accuracy, Precision, Recall, F1-score 등 지표를 계산하여 저장\n",
    "4. Confusion Matrix, ROC Curve, Precision-Recall Curve 등 다양한 시각화를 수행\n",
    "\n",
    "**필요 라이브러리**  \n",
    "- pandas  \n",
    "- numpy  \n",
    "- torch  \n",
    "- transformers  \n",
    "- matplotlib  \n",
    "- seaborn  \n",
    "- scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22135ff710ec2c9a",
   "metadata": {},
   "source": [
    "## 셀 1: 라이브러리 및 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe98b16-ba65-4624-9629-e0161df3075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54834a-4d8b-4916-a132-45d326308871",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.getcwd()  # 노트북을 프로젝트 루트에서 실행한다고 가정\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"processed\")\n",
    "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, \"checkpoints\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
    "VALID_CSV = os.path.join(DATA_DIR, \"valid.csv\")\n",
    "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "# 모델 파일 이름 (가장 성능이 좋은 체크포인트)\n",
    "BEST_MODEL_FILE = os.path.join(CHECKPOINT_DIR, \"best_model_epoch3.pt\")\n",
    "\n",
    "# 디바이스 설정 (가능하면 GPU, 아니면 CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ac6f8-9f83-4775-b567-f61ca58df76e",
   "metadata": {},
   "source": [
    "## 셀 2: 데이터 로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779dfee-d0c8-47f9-ab81-465686365cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) CSV 파일 로드\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "valid_df = pd.read_csv(VALID_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "# 2) 간단히 데이터 크기와 상위 5개 확인\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(train_df.head(), \"\\n\")\n",
    "\n",
    "print(\"Valid shape:\", valid_df.shape)\n",
    "print(valid_df.head(), \"\\n\")\n",
    "\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "print(test_df.head(), \"\\n\")\n",
    "\n",
    "# 3) 라벨 분포 살펴보기 (테스트셋)\n",
    "print(\"Test set label distribution:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64613ee7-0076-4a0d-922c-d74f1448dc14",
   "metadata": {},
   "source": [
    "## 셀 3: 텍스트 길이 분포 및 클래스 분포 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1bbd854-eded-4e85-947f-c91ed375290e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df, name \u001b[38;5;129;01min\u001b[39;00m [(train_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m), (valid_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid\u001b[39m\u001b[38;5;124m\"\u001b[39m), (test_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)]:\n\u001b[1;32m      2\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_length\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "for df, name in [(train_df, \"Train\"), (valid_df, \"Valid\"), (test_df, \"Test\")]:\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0834da67-97a3-4d85-aab1-b66ea87616ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_length\u001b[39m\u001b[38;5;124m'\u001b[39m], bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain 데이터 텍스트 단어 수 분포\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(train_df['text_length'], bins=50, kde=False, color=\"skyblue\")\n",
    "plt.title(\"Train 데이터 텍스트 단어 수 분포\")\n",
    "plt.xlabel(\"단어 수\")\n",
    "plt.ylabel(\"문장 개수\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35da287-3054-4f6a-8e11-2284baa1322c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      2\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mtest_df, palette\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalmon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest 데이터 클래스 분포\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 2) Test 클래스 분포 (ham/spam 비율)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='label', data=test_df, palette=['lightgreen', 'salmon'])\n",
    "plt.title(\"Test 데이터 클래스 분포\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e7712-f693-42d8-8532-a7c7f0c93bf2",
   "metadata": {},
   "source": [
    "## 셀 4: PyTorch Dataset & DataLoader 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d0d8f-df47-4138-8076-54e564808119",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamHamTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    test.csv 로드 → 토크나이저를 사용하여 input_ids, attention_mask, label 반환\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, tokenizer_name=\"bert-base-uncased\", max_length=128):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = str(row['text'])\n",
    "        label = int(row['label_id'])\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69bf13-066b-469e-95d6-37d98a8f137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SpamHamTestDataset(TEST_CSV, tokenizer_name=\"bert-base-uncased\", max_length=128)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac09356d-1503-475b-94f3-5adafa4bb0ed",
   "metadata": {},
   "source": [
    "## 5: 학습된 모델 불러오기 / 테스트셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e991d-0233-4545-8797-3ad354beeb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "model = SpamHamClassifier(model_name=model_name, num_labels=2)\n",
    "model.load_state_dict(torch.load(BEST_MODEL_FILE, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Loaded model from:\", BEST_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b2a67a4-6534-4950-bb9f-9926e35b266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # shape: (batch_size, 2)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        all_probs.extend(probs.tolist())\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4dae38-3018-4691-ac52-5cbfb1626d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Accuracy\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# 2) Precision, Recall, F1-score (binary)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "\n",
    "print(f\"Test Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-score      : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9970f763-09d7-4c7b-844f-167d4e8c0097",
   "metadata": {},
   "source": [
    "## 6: Confusion Matrix 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd1a62-3288-4afd-aec2-b04ece615e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[\"ham (0)\", \"spam (1)\"],\n",
    "            yticklabels=[\"ham (0)\", \"spam (1)\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4d7ac-a7ac-4f81-bc21-90bf577e2d2d",
   "metadata": {},
   "source": [
    "## 7: ROC Curve 및 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f77870d3-ae59-4d4c-940f-615f71a72a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(all_labels, all_probs)\n\u001b[1;32m      2\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0,1], [0,1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedac992-4178-4b7d-b408-80ba97752c94",
   "metadata": {},
   "source": [
    "## 8: Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152007a6-2d38-430c-8f7a-9f117a870106",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_points, recall_points, pr_thresholds = precision_recall_curve(all_labels, all_probs)\n",
    "pr_auc = auc(recall_points, precision_points)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(recall_points, precision_points, color=\"purple\", lw=2, label=f\"PR Curve (AUC = {pr_auc:.4f})\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee409ff-6543-4f1c-ba1f-07ac9ba759f2",
   "metadata": {},
   "source": [
    "## 9: 잘못 예측된 샘플(오분류) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d90ac-c035-4209-bf0d-05b0ea9a3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 원본과 예측 결과를 하나의 DataFrame에 합치기\n",
    "test_df['pred_label'] = all_preds\n",
    "test_df['prob_spam'] = all_probs\n",
    "\n",
    "# 오분류된 샘플 필터링\n",
    "wrong_df = test_df[test_df['label_id'] != test_df['pred_label']].copy()\n",
    "print(\"오분류 샘플 개수:\", len(wrong_df))\n",
    "display(wrong_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ee34c-f34d-4acb-b9e0-b7c07c0ab764",
   "metadata": {},
   "source": [
    "## 마무리\n",
    "\n",
    "- **Test Performance Metrics**: Accuracy, Precision, Recall, F1, ROC AUC, PR AUC 등을 DataFrame으로 정리하고 파일로 저장했습니다.\n",
    "- **시각화**: Confusion Matrix, ROC Curve, Precision-Recall Curve 등을 그려보았습니다.\n",
    "- **오분류 사례**: 실제로 모델이 잘못 예측한 샘플들을 살펴보며, 데이터 및 모델 개선 포인트를 찾을 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a7c10d-8788-4c85-b7c0-51b9658718c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
